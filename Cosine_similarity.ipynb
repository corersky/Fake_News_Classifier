{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine Similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk \n",
    "from nltk import *\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "from nltk.probability import FreqDist\n",
    "import string\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Information\n",
    "\n",
    "Given the title of a fake news article A and the title of a coming news article B, participants are asked to classify B into one of the three categories.\n",
    "\n",
    "- agreed: B talks about the same fake news as A\n",
    "- disagreed: B refutes the fake news in A\n",
    "- unrelated: B is unrelated to A\n",
    "\n",
    "### Data fields\n",
    "\n",
    "- id - the id of each news pair.\n",
    "- tid1 - the id of fake news title 1.\n",
    "- tid2 - the id of news title 2.\n",
    "- title1_zh - the fake news title 1 in Chinese.\n",
    "- title2_zh - the news title 2 in Chinese.\n",
    "- title1_en - the fake news title 1 in English.\n",
    "- title2_en - the news title 2 in English.\n",
    "- label - indicates the relation between the news pair: agreed/disagreed/unrelated.\n",
    "- The English titles are machine translated from the related Chinese titles. This may help participants from all background to get better understanding of the datasets. Participants are highly recommended to use the Chinese version titles to finish the task.\n",
    "\n",
    "### File type\n",
    "\n",
    "- train.csv - training data contains 320,767 news pairs in both Chinese and English. This file provides the only data you can use to finish the task. Using external data is not allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    \n",
    "    data = pd.read_csv(path)\n",
    "    data = data.set_index(\"id\")\n",
    "    data = data.sort_index()\n",
    "    \n",
    "    return data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach \n",
    "\n",
    "We have to come up with an idea to match Title 1 and Title 2  that can give a probability distribution describing the boundary condition for each of the three classes. The following are the ways we can do: -\n",
    "\n",
    "1) Let's try to find cosine similarity of the two titles. This can be our random variable and we can check whether it can help us to classify the random variable. \n",
    "\n",
    "-  Tokenize \n",
    "-  Form a uniform vector \n",
    "-  find the cosine of the two vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Cosine Similarity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) TextProcessing :- Three functions are created to find the final vector of each title. Combining all the three functions below, TextProcessing function is created.  \n",
    "- RemovePunctuation : Function to remove punctuaiton from the text documents \n",
    "- Tokenize : Function to tokenize the text document. Returns a list of array where each element is token. \n",
    "- StopWordRemoval : Function to remove the Stop words from the text documents. \n",
    "- Lemmatization : Function to remove the prefix and suffix of the words and return the lemma of the word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to remove Punctuation from the string, even attached to the word. \n",
    "def RemovePunctuation(my_str):\n",
    "    punctuations = string.punctuation\n",
    "    no_punct = \"\"\n",
    "    for char in my_str:\n",
    "        if char not in punctuations:\n",
    "            no_punct = no_punct + char.lower()\n",
    "            \n",
    "    return no_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokenize the string\n",
    "def Tokenize(my_str):\n",
    "    text = my_str.split()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove Stop Word \n",
    "stopwords = set(stopwords.words('english'))\n",
    "def StopWordRemoval(my_str):\n",
    "    \n",
    "    l = [word for word in my_str if word not in stopwords]\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove Suffix and prefix from the word. \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemma(my_str):\n",
    "    \n",
    "    l = [lemmatizer.lemmatize(word) for word in my_str]\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Applying the above functions altogether\n",
    "def TextProcessing(text):\n",
    "    \n",
    "    text = RemovePunctuation(text)\n",
    "    text = Tokenize(text)\n",
    "    text = StopWordRemoval(text)\n",
    "    text = lemma(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) BagOfWords :- This function create a set of all the unique words (tokens) in the two titles (title 1 and title 2). We shall use this to create a seperate column in the dataframe consisting of all the unique words in the two titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BagOfWords(list_str):\n",
    "    dic =  list(set(list_str))\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) TermFrequency :- This function will find the frequency of each word of the dictionary in the given list. This function returns a  frequency vector of a size equivalent to the size of the dictionary. In can take a nested list in the form of Numpy array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TermFrequency(dictionary, text ):\n",
    "    length = len(dictionary)\n",
    "    freq_list = []\n",
    "    for ii in range(length):\n",
    "        dic_list = dictionary[ii]\n",
    "        text_list = text[ii]\n",
    "        freq = []\n",
    "        for i in range(len(dic_list)):\n",
    "            freq.append(text_list.count(dic_list[i]))\n",
    "        freq_list.append(np.array(freq))\n",
    "        \n",
    "    return np.array(freq_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) L2 and Cosine : L2 function is calculate the L2 norm of the vector on the other end, Cosine is calculate the cosine of the angle between the two vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L2(vector):\n",
    "    norm_value = np.linalg.norm(vector)\n",
    "    return norm_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cosine(fr1, fr2):\n",
    "    cos = np.dot(fr1, fr2)/(L2(fr1)*L2(fr2))\n",
    "    return cos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**********************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Applying the above define funcitons on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    \"\"\"Creating another dataframe in to process the text \"\"\"\n",
    "    df = data[[\"title1_en\", \"title2_en\"]]\n",
    "    \n",
    "    \"\"\"Applying TextProcessing function\"\"\"\n",
    "    df[\"title1_en\"] = df[\"title1_en\"].apply(lambda x: TextProcessing(x))\n",
    "    df[\"title2_en\"] = df[\"title2_en\"].apply(lambda x: TextProcessing(x))\n",
    "    \n",
    "    \"\"\"Creating Dictionary column by adding tile1_en and title2_en and applying Dictionary function to\"\"\"\n",
    "    df[\"BagOfWords\"] = df['title1_en'] + df[\"title2_en\"]\n",
    "    df.BagOfWords = df.BagOfWords.map(BagOfWords)\n",
    "    \n",
    "    # Creating \"TF1\" and \"TF2\" variable containing a list of Frequency for each word in title1 and title 2 and\n",
    "    # adding a column for Cosine Similarity. \n",
    "    df[\"TF1\"] = TermFrequency(df.BagOfWords.values, df.title1_en.values)\n",
    "    df[\"TF2\"] = TermFrequency(df.BagOfWords.values, df.title2_en.values)\n",
    "    df[\"Cosine_similarity\"] = np.vectorize(Cosine)(df[\"TF1\"], df[\"TF2\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Cosine of the vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tid1</th>\n",
       "      <th>tid2</th>\n",
       "      <th>title1_zh</th>\n",
       "      <th>title2_zh</th>\n",
       "      <th>title1_en</th>\n",
       "      <th>title2_en</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017养老保险又新增两项，农村老人人人可申领，你领到了吗</td>\n",
       "      <td>警方辟谣“鸟巢大会每人领5万” 仍有老人坚持进京</td>\n",
       "      <td>There are two new old-age insurance benefits f...</td>\n",
       "      <td>Police disprove \"bird's nest congress each per...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>\"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港</td>\n",
       "      <td>GDP首超香港？深圳澄清：还差一点点……</td>\n",
       "      <td>\"If you do not come to Shenzhen, sooner or lat...</td>\n",
       "      <td>The GDP overtopped Hong Kong? Shenzhen clarifi...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>\"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港</td>\n",
       "      <td>去年深圳GDP首超香港？深圳统计局辟谣：还差611亿</td>\n",
       "      <td>\"If you do not come to Shenzhen, sooner or lat...</td>\n",
       "      <td>Shenzhen's GDP topped Hong Kong last year? She...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>\"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港</td>\n",
       "      <td>深圳GDP首超香港？深圳统计局辟谣：只是差距在缩小</td>\n",
       "      <td>\"If you do not come to Shenzhen, sooner or lat...</td>\n",
       "      <td>Shenzhen's GDP outstrips Hong Kong? Shenzhen S...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>\"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港</td>\n",
       "      <td>深圳GDP首超香港？统计局辟谣：未超但差距再度缩小</td>\n",
       "      <td>\"If you do not come to Shenzhen, sooner or lat...</td>\n",
       "      <td>Shenzhen's GDP overtakes Hong Kong? Bureau of ...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tid1  tid2                          title1_zh                   title2_zh  \\\n",
       "id                                                                              \n",
       "0      0     1      2017养老保险又新增两项，农村老人人人可申领，你领到了吗    警方辟谣“鸟巢大会每人领5万” 仍有老人坚持进京   \n",
       "1      2     4  \"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港        GDP首超香港？深圳澄清：还差一点点……   \n",
       "2      2     5  \"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港  去年深圳GDP首超香港？深圳统计局辟谣：还差611亿   \n",
       "3      2     3  \"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港   深圳GDP首超香港？深圳统计局辟谣：只是差距在缩小   \n",
       "4      2     8  \"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港   深圳GDP首超香港？统计局辟谣：未超但差距再度缩小   \n",
       "\n",
       "                                            title1_en  \\\n",
       "id                                                      \n",
       "0   There are two new old-age insurance benefits f...   \n",
       "1   \"If you do not come to Shenzhen, sooner or lat...   \n",
       "2   \"If you do not come to Shenzhen, sooner or lat...   \n",
       "3   \"If you do not come to Shenzhen, sooner or lat...   \n",
       "4   \"If you do not come to Shenzhen, sooner or lat...   \n",
       "\n",
       "                                            title2_en      label  \n",
       "id                                                                \n",
       "0   Police disprove \"bird's nest congress each per...  unrelated  \n",
       "1   The GDP overtopped Hong Kong? Shenzhen clarifi...  unrelated  \n",
       "2   Shenzhen's GDP topped Hong Kong last year? She...  unrelated  \n",
       "3   Shenzhen's GDP outstrips Hong Kong? Shenzhen S...  unrelated  \n",
       "4   Shenzhen's GDP overtakes Hong Kong? Bureau of ...  unrelated  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Loading data\n",
    "data = load_data(\"train.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the Cosine of the vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocess(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title1_en</th>\n",
       "      <th>title2_en</th>\n",
       "      <th>BagOfWords</th>\n",
       "      <th>TF1</th>\n",
       "      <th>TF2</th>\n",
       "      <th>Cosine_similarity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[two, new, oldage, insurance, benefit, old, pe...</td>\n",
       "      <td>[police, disprove, bird, nest, congress, perso...</td>\n",
       "      <td>[old, got, congress, new, insurance, bird, old...</td>\n",
       "      <td>[1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, ...</td>\n",
       "      <td>[1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, ...</td>\n",
       "      <td>0.163299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[come, shenzhen, sooner, later, son, also, com...</td>\n",
       "      <td>[gdp, overtopped, hong, kong, shenzhen, clarif...</td>\n",
       "      <td>[kong, le, also, shenzhen, hong, clarified, co...</td>\n",
       "      <td>[1, 1, 1, 2, 1, 0, 2, 1, 0, 1, 0, 1, 1, 1, 0, ...</td>\n",
       "      <td>[1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, ...</td>\n",
       "      <td>0.385758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[come, shenzhen, sooner, later, son, also, com...</td>\n",
       "      <td>[shenzhens, gdp, topped, hong, kong, last, yea...</td>\n",
       "      <td>[kong, bureau, billion, le, also, last, topped...</td>\n",
       "      <td>[1, 0, 0, 1, 1, 0, 0, 2, 0, 1, 2, 1, 0, 0, 1, ...</td>\n",
       "      <td>[1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, ...</td>\n",
       "      <td>0.349927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[come, shenzhen, sooner, later, son, also, com...</td>\n",
       "      <td>[shenzhens, gdp, outstrips, hong, kong, shenzh...</td>\n",
       "      <td>[kong, bureau, narrowing, le, also, shenzhen, ...</td>\n",
       "      <td>[1, 0, 0, 1, 1, 2, 0, 1, 2, 0, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, ...</td>\n",
       "      <td>0.314970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[come, shenzhen, sooner, later, son, also, com...</td>\n",
       "      <td>[shenzhens, gdp, overtakes, hong, kong, bureau...</td>\n",
       "      <td>[kong, bureau, le, also, shenzhen, shrink, she...</td>\n",
       "      <td>[1, 0, 1, 1, 2, 0, 0, 1, 0, 0, 2, 0, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, ...</td>\n",
       "      <td>0.188982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            title1_en  \\\n",
       "id                                                      \n",
       "0   [two, new, oldage, insurance, benefit, old, pe...   \n",
       "1   [come, shenzhen, sooner, later, son, also, com...   \n",
       "2   [come, shenzhen, sooner, later, son, also, com...   \n",
       "3   [come, shenzhen, sooner, later, son, also, com...   \n",
       "4   [come, shenzhen, sooner, later, son, also, com...   \n",
       "\n",
       "                                            title2_en  \\\n",
       "id                                                      \n",
       "0   [police, disprove, bird, nest, congress, perso...   \n",
       "1   [gdp, overtopped, hong, kong, shenzhen, clarif...   \n",
       "2   [shenzhens, gdp, topped, hong, kong, last, yea...   \n",
       "3   [shenzhens, gdp, outstrips, hong, kong, shenzh...   \n",
       "4   [shenzhens, gdp, overtakes, hong, kong, bureau...   \n",
       "\n",
       "                                           BagOfWords  \\\n",
       "id                                                      \n",
       "0   [old, got, congress, new, insurance, bird, old...   \n",
       "1   [kong, le, also, shenzhen, hong, clarified, co...   \n",
       "2   [kong, bureau, billion, le, also, last, topped...   \n",
       "3   [kong, bureau, narrowing, le, also, shenzhen, ...   \n",
       "4   [kong, bureau, le, also, shenzhen, shrink, she...   \n",
       "\n",
       "                                                  TF1  \\\n",
       "id                                                      \n",
       "0   [1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, ...   \n",
       "1   [1, 1, 1, 2, 1, 0, 2, 1, 0, 1, 0, 1, 1, 1, 0, ...   \n",
       "2   [1, 0, 0, 1, 1, 0, 0, 2, 0, 1, 2, 1, 0, 0, 1, ...   \n",
       "3   [1, 0, 0, 1, 1, 2, 0, 1, 2, 0, 1, 1, 1, 1, 1, ...   \n",
       "4   [1, 0, 1, 1, 2, 0, 0, 1, 0, 0, 2, 0, 1, 1, 1, ...   \n",
       "\n",
       "                                                  TF2  Cosine_similarity  \n",
       "id                                                                        \n",
       "0   [1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, ...           0.163299  \n",
       "1   [1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, ...           0.385758  \n",
       "2   [1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, ...           0.349927  \n",
       "3   [1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, ...           0.314970  \n",
       "4   [1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, ...           0.188982  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a dataframe with Cosine_similarity and the lebel\n",
    "prob_dist = pd.concat([df.Cosine_similarity, data.label], axis=1)\n",
    "prob_dist = prob_dist.fillna(value=0)\n",
    "prob_dist = prob_dist.reset_index()[[\"Cosine_similarity\",\"label\"]]\n",
    "\n",
    "## Class wise data segregation\n",
    "unrelated =  prob_dist[prob_dist[\"label\"] == 'unrelated']\n",
    "agreed = prob_dist[prob_dist[\"label\"] == 'agreed']\n",
    "disagreed = prob_dist[prob_dist[\"label\"] == 'disagreed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(unrelated.Cosine_similarity/unrelated.Cosine_similarity.std() , label= \"Unrelated\", bins= 100)\n",
    "plt.hist(agreed.Cosine_similarity/agreed.Cosine_similarity.std(), label= \"Agreed\", bins= 100)\n",
    "plt.hist(disagreed.Cosine_similarity/disagreed.Cosine_similarity.std() , label= \"Disagreed\", bins= 100)\n",
    "plt.ylim(0,6500)\n",
    "plt.xlim(0.05,6)\n",
    "plt.xlabel(\"Normalized Cosine Similarity Score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Cosine Similarity Score distribution\")\n",
    "plt.legend()\n",
    "plt.savefig(\"Cosine_similarity_distribution.png\", dpi= 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "\n",
    "def classifier(data, label, size):\n",
    "        \"\"\"Classification analysis is done using 4 different classifiers. Function returns the performance score\n",
    "        of each of the classifier\"\"\"\n",
    "        from sklearn.metrics import jaccard_similarity_score\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=size, random_state=42)\n",
    "        \n",
    "        # Bayesian Classifier \n",
    "        gnb = GaussianNB()\n",
    "        gnb_clf = gnb.fit(X_train, y_train)\n",
    "        score1 = gnb_clf.score(X_test, y_test)\n",
    "        y_pred1 = gnb_clf.predict(X_test)\n",
    "        js1 = jaccard_similarity_score(y_test, y_pred1)\n",
    "        \n",
    "        # Logisitic Regression Classifier\n",
    "        logisitc_clf= LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial')\n",
    "        logistic_clf = logisitc_clf.fit(X_train, y_train)\n",
    "        score2 = logistic_clf.score(X_test, y_test)\n",
    "        y_pred2 = logistic_clf.predict(X_test)\n",
    "        js2 = jaccard_similarity_score(y_test, y_pred2)\n",
    "        \n",
    "        # Random Forest Classifier \n",
    "        Randomforest_clf = RandomForestClassifier(n_estimators=100, max_depth=2,random_state=0)\n",
    "        rfc_clf = Randomforest_clf.fit(X_train, y_train)\n",
    "        score3 = rfc_clf.score(X_test, y_test)\n",
    "        y_pred3 = rfc_clf.predict(X_test)\n",
    "        js3 = jaccard_similarity_score(y_test, y_pred3)\n",
    "        \n",
    "        # LDA \n",
    "        LDA = LinearDiscriminantAnalysis()\n",
    "        LDA_clf = LDA.fit(X_train, y_train)\n",
    "        score4 = LDA_clf.score(X_test, y_test)\n",
    "        y_pred4 = LDA_clf.predict(X_test)\n",
    "        js4 = jaccard_similarity_score(y_test, y_pred4)\n",
    "\n",
    "        \n",
    "        print(\"Naive Bayes Classifier score:=  \" + str(score1)) #+ \"&\" + str(js1)), \\\n",
    "        print(\"Logistic Regression Classifier score:=  \" + str(score2))#+ \"&\" + str(js2)), \\\n",
    "        print(\"Random Forest Classifier score:=  \" + str(score3))#+ \"&\" + str(js3)), \\\n",
    "        print(\"LDA Classifier score:=  \" + str(score4))#+ \"&\" + str(js4))\n",
    "        \n",
    "        return gnb_clf, logistic_clf, rfc_clf, LDA_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConfusionMatrix(y_true, y_pred, classes,normalize=True, title=None, cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "            \n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dummy = [1]*320492\n",
    "X = pd.concat([prob_dist[[\"Cosine_similarity\"]], pd.DataFrame(Dummy)], axis=1)\n",
    "X.columns = ['Cosine_similarity', \"Dummy\"]\n",
    "y = prob_dist[['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classifier score:=  0.7586086392172036\n",
      "Logistic Regression Classifier score:=  0.7583340613806273\n",
      "Random Forest Classifier score:=  0.752118617625401\n",
      "LDA Classifier score:=  0.7580594835440511\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(GaussianNB(priors=None, var_smoothing=1e-09),\n",
       " LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "           n_jobs=None, penalty='l2', random_state=0, solver='lbfgs',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       " RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "             oob_score=False, random_state=0, verbose=0, warm_start=False),\n",
       " LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "               solver='svd', store_covariance=False, tol=0.0001))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(X,y , 0.25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
